{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import cv2\n",
    "from faced import FaceDetector\n",
    "from faced.utils import annotate_image\n",
    "\n",
    "img_path=\"02-still-for-america-room-loop-articleLarge.jpg\"\n",
    "\n",
    "face_detector = FaceDetector()\n",
    "img = cv2.imread(img_path)\n",
    "rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "thresh=0.85\n",
    "bboxes = face_detector.predict(rgb_img, thresh)\n",
    "ann_img = annotate_image(img, bboxes)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('image',ann_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Detection_Faces(img_path):\n",
    "    face_detector = FaceDetector()\n",
    "    img = cv2.imread(img_path)\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    thresh=0.85\n",
    "    bboxes = face_detector.predict(rgb_img, thresh)\n",
    "    return bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 210, 62, 75, 0.93399006)\n"
     ]
    }
   ],
   "source": [
    "print(bboxes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Detection_Faces(img_path):\n",
    "    face_detector = FaceDetector()\n",
    "    img = cv2.imread(img_path)\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    thresh=0.85\n",
    "    bboxes = face_detector.predict(rgb_img, thresh)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceDetection_to_Cv2Rectangles(bboxes):\n",
    "    \n",
    "    if not bboxes:\n",
    "        return \"Nothing\"\n",
    "    i=0\n",
    "    x=bboxes[0][0]\n",
    "    y=bboxes[0][1]\n",
    "    w=bboxes[0][2]\n",
    "    h=bboxes[0][3]\n",
    "    StartingPoint_x=int(x - w/2)\n",
    "    StartingPoint_y= int(y - h/2)\n",
    "    FinalPoint_x=int(x + w/2)\n",
    "    FinalPoint_y=int(y + h/2)\n",
    "    Color=(0, 255, 0)\n",
    "    thickness=3\n",
    "    \n",
    "\n",
    "    return StartingPoint_x,StartingPoint_y,FinalPoint_x,FinalPoint_y,Color,thickness\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"02-still-for-america-room-loop-articleLarge.jpg\"\n",
    "bboxes=Detection_Faces(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "StartingPoint_x,StartingPoint_y,FinalPoint_x,FinalPoint_y,Color,thickness=FaceDetection_to_Cv2Rectangles(bboxes)\n",
    "image = cv2.rectangle(img, (StartingPoint_x, StartingPoint_y), (FinalPoint_x, FinalPoint_y),\n",
    "                      Color, thickness)\n",
    "\n",
    "cv2.imshow('image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "from FR_UtilsV2 import *\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "from FR_UtilsV2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../WebCamDetection/opencv_frame_0.jpg written!\n",
      "../WebCamDetection/opencv_frame_1.jpg written!\n",
      "../WebCamDetection/opencv_frame_2.jpg written!\n",
      "../WebCamDetection/opencv_frame_3.jpg written!\n",
      "../WebCamDetection/opencv_frame_4.jpg written!\n",
      "../WebCamDetection/opencv_frame_5.jpg written!\n",
      "../WebCamDetection/opencv_frame_6.jpg written!\n",
      "../WebCamDetection/opencv_frame_7.jpg written!\n",
      "../WebCamDetection/opencv_frame_8.jpg written!\n",
      "../WebCamDetection/opencv_frame_9.jpg written!\n",
      "../WebCamDetection/opencv_frame_10.jpg written!\n",
      "../WebCamDetection/opencv_frame_11.jpg written!\n",
      "../WebCamDetection/opencv_frame_12.jpg written!\n",
      "../WebCamDetection/opencv_frame_13.jpg written!\n",
      "../WebCamDetection/opencv_frame_14.jpg written!\n",
      "../WebCamDetection/opencv_frame_15.jpg written!\n",
      "../WebCamDetection/opencv_frame_16.jpg written!\n",
      "../WebCamDetection/opencv_frame_17.jpg written!\n",
      "../WebCamDetection/opencv_frame_18.jpg written!\n",
      "../WebCamDetection/opencv_frame_19.jpg written!\n",
      "../WebCamDetection/opencv_frame_20.jpg written!\n",
      "../WebCamDetection/opencv_frame_21.jpg written!\n",
      "../WebCamDetection/opencv_frame_22.jpg written!\n",
      "../WebCamDetection/opencv_frame_23.jpg written!\n",
      "../WebCamDetection/opencv_frame_24.jpg written!\n",
      "../WebCamDetection/opencv_frame_25.jpg written!\n",
      "../WebCamDetection/opencv_frame_26.jpg written!\n",
      "../WebCamDetection/opencv_frame_27.jpg written!\n",
      "../WebCamDetection/opencv_frame_28.jpg written!\n",
      "../WebCamDetection/opencv_frame_29.jpg written!\n",
      "../WebCamDetection/opencv_frame_30.jpg written!\n",
      "../WebCamDetection/opencv_frame_31.jpg written!\n",
      "../WebCamDetection/opencv_frame_32.jpg written!\n",
      "../WebCamDetection/opencv_frame_33.jpg written!\n",
      "../WebCamDetection/opencv_frame_34.jpg written!\n",
      "../WebCamDetection/opencv_frame_35.jpg written!\n",
      "../WebCamDetection/opencv_frame_36.jpg written!\n",
      "../WebCamDetection/opencv_frame_37.jpg written!\n",
      "../WebCamDetection/opencv_frame_38.jpg written!\n",
      "../WebCamDetection/opencv_frame_39.jpg written!\n",
      "../WebCamDetection/opencv_frame_40.jpg written!\n",
      "../WebCamDetection/opencv_frame_41.jpg written!\n",
      "../WebCamDetection/opencv_frame_42.jpg written!\n",
      "../WebCamDetection/opencv_frame_43.jpg written!\n",
      "../WebCamDetection/opencv_frame_44.jpg written!\n",
      "../WebCamDetection/opencv_frame_45.jpg written!\n",
      "../WebCamDetection/opencv_frame_46.jpg written!\n",
      "../WebCamDetection/opencv_frame_47.jpg written!\n",
      "../WebCamDetection/opencv_frame_48.jpg written!\n",
      "../WebCamDetection/opencv_frame_49.jpg written!\n",
      "../WebCamDetection/opencv_frame_50.jpg written!\n",
      "../WebCamDetection/opencv_frame_51.jpg written!\n",
      "../WebCamDetection/opencv_frame_52.jpg written!\n",
      "../WebCamDetection/opencv_frame_53.jpg written!\n",
      "../WebCamDetection/opencv_frame_54.jpg written!\n",
      "../WebCamDetection/opencv_frame_55.jpg written!\n",
      "../WebCamDetection/opencv_frame_56.jpg written!\n",
      "../WebCamDetection/opencv_frame_57.jpg written!\n",
      "../WebCamDetection/opencv_frame_58.jpg written!\n",
      "../WebCamDetection/opencv_frame_59.jpg written!\n",
      "../WebCamDetection/opencv_frame_60.jpg written!\n",
      "../WebCamDetection/opencv_frame_61.jpg written!\n",
      "../WebCamDetection/opencv_frame_62.jpg written!\n",
      "../WebCamDetection/opencv_frame_63.jpg written!\n",
      "../WebCamDetection/opencv_frame_64.jpg written!\n",
      "../WebCamDetection/opencv_frame_65.jpg written!\n",
      "../WebCamDetection/opencv_frame_66.jpg written!\n",
      "../WebCamDetection/opencv_frame_67.jpg written!\n",
      "../WebCamDetection/opencv_frame_68.jpg written!\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "Photo_Dict={}\n",
    "Identity_Array=[]\n",
    "suma=0\n",
    "count=0\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    camaraOn=True\n",
    "    i=-1\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame,'',(470,70),font,1,(0,0,0),2)\n",
    "    \n",
    "    cv2.imshow(\"test\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    \n",
    "    elif k%256 == 32:\n",
    "        while camaraOn==True:\n",
    "            i=i+1\n",
    "            \n",
    "            if i >1:\n",
    "              cv2.rectangle(frame, (StartingPoint_x, StartingPoint_y), (FinalPoint_x, FinalPoint_y),\n",
    "                      Color, thickness)\n",
    "              \n",
    "              cv2.imshow(\"test\", frame)\n",
    "            \n",
    "            a = cv2.waitKey(1)\n",
    "            cv2.waitKey(10)\n",
    "            ret, frame = cam.read()\n",
    "            img_name = \"../WebCamDetection/opencv_frame_{}.jpg\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "            \n",
    "            with open('../WebCamDetection/opencv_frame_'+str(i)+'.jpg', 'r+b') as f:\n",
    "                with Image.open(f) as image:\n",
    "                    image.save('../WebCamDetection/opencv_frame_'+str(i)+'.jpg', image.format)\n",
    "                    bboxes = Detection_Faces(\"../WebCamDetection/opencv_frame_\"+str(i)+\".jpg\")\n",
    "                    if not bboxes:\n",
    "                        StartingPoint_x=0\n",
    "                        StartingPoint_y=0\n",
    "                        FinalPoint_x=0\n",
    "                        FinalPoint_y=0\n",
    "                        Color=0\n",
    "                        thickness=0\n",
    "                    else:\n",
    "                        StartingPoint_x,StartingPoint_y,FinalPoint_x,FinalPoint_y,Color,thickness=FaceDetection_to_Cv2Rectangles(bboxes)\n",
    "                        \n",
    "            if a%256 == 27:\n",
    "                camaraOn=False\n",
    "                break\n",
    "            ret, frame = cam.read()\n",
    "            cv2.imshow(\"test\", frame)\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def Crop_Image_to_Face(img_path,i):\n",
    "    img = Image.open(img_path)\n",
    "    bboxes=Detection_Faces(img_path)\n",
    "    StartingPoint_x,StartingPoint_y,FinalPoint_x,FinalPoint_y,Color,thickness=FaceDetection_to_Cv2Rectangles(bboxes)\n",
    "    img2 = img.crop((StartingPoint_x, StartingPoint_y, FinalPoint_x, FinalPoint_y))\n",
    "    im = img2.resize((96,96),Image.ANTIALIAS)\n",
    "    im.save(\"../WebCamResize/Face_Resize_\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 19:35:43.701580 16176 deprecation.py:506] From E:\\ApplicationsFast\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not soumah, please go away\n",
      "Not in the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.73222095, 'soumah')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)\n",
    "\n",
    "database = {}\n",
    "database[\"Luis\"] = img_to_encoding(\"../images/Luis.jpg\", FRmodel)\n",
    "database[\"soumah\"] = img_to_encoding(\"../images/Face_Resize_0.jpg\", FRmodel)\n",
    "\n",
    "verify(\"../WebCamResize/Face_Resize_9.jpg\", \"soumah\", database, FRmodel)\n",
    "\n",
    "who_is_it(\"../WebCamResize/Face_Resize_1.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9536766, 'soumah')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"../WebCamResize/Face_Resize_3.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "Photo_Dict={}\n",
    "Identity_Array=[]\n",
    "suma=0\n",
    "count=0\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    camaraOn=True\n",
    "    i=-1\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame,'',(470,70),font,1,(0,0,0),2)\n",
    "    \n",
    "    cv2.imshow(\"test\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    \n",
    "    elif k%256 == 32:\n",
    "        while camaraOn==True:\n",
    "            i=i+1\n",
    "            \n",
    "            if i >1:\n",
    "              cv2.rectangle(frame, (StartingPoint_x, StartingPoint_y), (FinalPoint_x, FinalPoint_y),\n",
    "                      Color, thickness)\n",
    "              cv2.putText(frame,Name_Placer,(470,70),font,1,(0,0,0),2)\n",
    "              cv2.imshow(\"test\", frame)\n",
    "            \n",
    "            a = cv2.waitKey(1)\n",
    "            cv2.waitKey(10)\n",
    "            ret, frame = cam.read()\n",
    "            img_name = \"../WebCamDetection/opencv_frame_{}.jpg\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "            \n",
    "            with open('../WebCamDetection/opencv_frame_'+str(i)+'.jpg', 'r+b') as f:\n",
    "                with Image.open(f) as image:\n",
    "                    image_path='../WebCamDetection/opencv_frame_'+str(i)+'.jpg'\n",
    "                    image.save('../WebCamDetection/opencv_frame_'+str(i)+'.jpg', image.format)\n",
    "                    bboxes = Detection_Faces(\"../WebCamDetection/opencv_frame_\"+str(i)+\".jpg\")\n",
    "                    if not bboxes:\n",
    "                        StartingPoint_x=0\n",
    "                        StartingPoint_y=0\n",
    "                        FinalPoint_x=0\n",
    "                        FinalPoint_y=0\n",
    "                        Color=0\n",
    "                        thickness=0\n",
    "                    else:\n",
    "                        StartingPoint_x,StartingPoint_y,FinalPoint_x,FinalPoint_y,Color,thickness=FaceDetection_to_Cv2Rectangles(bboxes)\n",
    "                        Crop_Image_to_Face(img_path,i)\n",
    "                        min_dist , identity =who_is_it(\"../WebCamResize/Face_Resize_\"+str(i)+\".jpg\", database, FRmodel)\n",
    "                        Name_Placer=\"Not Known\"\n",
    "                        if min_dist > 0.96:\n",
    "                            print(\"Not in the database.\")\n",
    "\n",
    "                            Name_Placer=\"Not Known\"\n",
    "                            cv2.putText(frame,Name_Placer,(470,70),font,1,(0,0,0),2)\n",
    "                            cv2.imshow(\"test\", frame)\n",
    "                            \n",
    "                            print(min_dist)\n",
    "                        else:\n",
    "                            print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "                            Name_Placer=identity\n",
    "            if a%256 == 27:\n",
    "                camaraOn=False\n",
    "                break\n",
    "            ret, frame = cam.read()\n",
    "            cv2.imshow(\"test\", frame)\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
